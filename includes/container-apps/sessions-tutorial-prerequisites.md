---
author: anthonychu
ms.service: container-apps
ms.topic:  include
ms.date: 05/08/2024
ms.author: antchu
---

## Prerequisites

- An Azure account with an active subscription.
  - If you don't have one, you [can create one for free](https://azure.microsoft.com/free/).
- Install the [Azure CLI](/cli/azure/install-azure-cli).
- Git.
- Python 3.10 or later.

## Create Azure resources

The sample app in this quickstart uses an LLM from Azure OpenAI. It also uses Azure Container Apps sessions to run code generated by the LLM.

1. Update the Azure CLI to the latest version.

   ```bash
    az upgrade
    ```

1. Remove the Azure Container Apps extension if it's already installed and install a preview version the Azure Container Apps extension containing commands for sessions:

    ```bash
    az extension remove --name containerapp
    az extension add \
        --name containerapp \
        --allow-preview true -y
    ```

1. Sign in to Azure:

   ```bash
   az login
   ```

1. Set the variables used in this quickstart:

    ```bash
    RESOURCE_GROUP_NAME=aca-sessions-tutorial
    AZURE_OPENAI_LOCATION=swedencentral
    AZURE_OPENAI_NAME=<UNIQUE_OPEN_AI_NAME>
    SESSION_POOL_LOCATION=eastasia
    SESSION_POOL_NAME=code-interpreter-pool
    ```

    Replace `<UNIQUE_OPEN_AI_NAME>` with a unique name to create your Azure OpenAI account.

1. Create a resource group:

   ```bash
   az group create --name $RESOURCE_GROUP_NAME --location $SESSION_POOL_LOCATION
   ```

1. Create an Azure OpenAI account:

    ```bash
    az cognitiveservices account create \
        --name $AZURE_OPENAI_NAME \
        --resource-group $RESOURCE_GROUP_NAME \
        --location $AZURE_OPENAI_LOCATION \
        --kind OpenAI \
        --sku s0 \
        --custom-domain $AZURE_OPENAI_NAME
    ```

1. Create a GPT 3.5 Turbo model deployment named `gpt-35-turbo` in the Azure OpenAI account:

    ```bash
    az cognitiveservices account deployment create \
        --resource-group $RESOURCE_GROUP_NAME \
        --name $AZURE_OPENAI_NAME \
        --deployment-name gpt-35-turbo \
        --model-name gpt-35-turbo \
        --model-version "1106" \
        --model-format OpenAI \
        --sku-capacity "100" \
        --sku-name "Standard"
    ```

1. Create a code interpreter session pool:

    ```bash
    az containerapp sessionpool create \
        --name $SESSION_POOL_NAME \
        --resource-group $RESOURCE_GROUP_NAME \
        --location $SESSION_POOL_LOCATION \
        --max-sessions 100 \
        --container-type PythonLTS \
        --cooldown-period 300
    ```
