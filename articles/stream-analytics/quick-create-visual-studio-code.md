---
title: Create a Stream Analytics job using Visual Studio Code
description: This quickstart shows you how to create a Stream Analytics job using the ASA extension for Visual Studio Code.
ms.service: azure-stream-analytics
author: ahartoon
ms.author: anboisve
ms.date: 12/17/2024
ms.topic: quickstart
ms.custom: mvc, mode-ui
#Customer intent: As an IT admin/developer, I want to create a Stream Analytics job, configure input and output, and analyze data by using Visual Studio Code.
---

# Quickstart: Create a Stream Analytics job using Visual Studio Code
In this quickstart, you create, run and submit an Azure Stream Analytics (ASA) job using the ASA Tools extension for Visual Studio Code in your local machine. You learn to build an ASA job that reads real-time streaming data from IoT Hub and filters events with a temperature greater than 27Â°. The output results are sent to a file in blob storage. The input data used in this quickstart is generated by a Raspberry Pi online simulator.

> [!NOTE]
> Visual Studio Code tools don't support jobs in the China East, China North, Germany Central, and Germany NorthEast regions.

## Prerequisites
* Azure subscription. If you don't have an Azure subscription, create a [free account](https://azure.microsoft.com/free/).
* [Visual Studio Code](https://code.visualstudio.com/).

## Install the Azure Stream Analytics Tools extension

1. Open Visual Studio Code (VS Code).
2. From **Extensions** on the left pane, search for **stream analytics** and select **Install** on the **Azure Stream Analytics Tools** extension.

    :::image type="content" source="./media/quick-create-visual-studio-code/install-extension.png" alt-text="Screenshot showing the Extensions page of Visual Studio Code with an option to install Stream Analytics extension.":::

3. After it's installed, select the **Azure** icon on the activity bar and sign in to Azure.

    :::image type="content" source="./media/quick-create-visual-studio-code/azure-sign-in.png" alt-text="Screenshot showing how to sign in to Azure.":::

4. Once you're signed in, you can see the subscriptions under your Azure account.

> [!NOTE] 
> The ASA Tools extension will automatically sign you in every time you open VS Code. If your account has two-factor authentication, we recommend that you use phone authentication rather than using a PIN. To sign out your Azure account, press `Ctrl + Shift + P` and enter `Azure: Sign Out`.

## Run the IoT simulator

1. Open the [Raspberry Pi Azure IoT Online Simulator](https://azure-samples.github.io/raspberry-pi-web-simulator/).
2. Replace the placeholder in Line 15 with the Azure IoT Hub device connection string you saved in a previous section.
3. Select **Run**. The output should show the sensor data and messages that are being sent to your IoT Hub.

   :::image type="content" source="./media/stream-analytics-quick-create-portal/ras-pi-connection-string.png" lightbox="./media/stream-analytics-quick-create-portal/ras-pi-connection-string.png" alt-text="Screenshot showing the **Raspberry Pi Azure IoT Online Simulator** page with the sample query."::: 

    > [!IMPORTANT]
    > Select **Reset** after a few minutes to reset the connection string.

## Create blob storage

1. From the upper-left corner of the Azure portal, select **Create a resource** > **Storage** > **Storage account**.

    :::image type="content" source="./media/quick-create-visual-studio-code/create-storage-account-menu.png" alt-text="Screenshot showing the Create storage account menu.":::   

2. In the **Create storage account** pane, enter a storage account name, location, and resource group. Choose the same location and resource group as the IoT hub that you created. Then select **Review** and **Create** to create the storage account.

    :::image type="content" source="./media/quick-create-visual-studio-code/create-storage-account.png" alt-text="Screenshot showing the Create storage account page."::: 
  
3. On the **Storage account** page, select **Containers** on the left menu, and then select **+ Container** on the command bar.

    :::image type="content" source="./media/quick-create-visual-studio-code/add-blob-container-menu.png" alt-text="Screenshot showing the Containers page.":::   

4. From the **New container** page, provide a **name** for your container, leave **Public access level** as **Private (no anonymous access)**, and select **OK**.

    :::image type="content" source="./media/quick-create-visual-studio-code/create-blob-container.png" alt-text="Screenshot showing the creation of a blob container page.":::   

## Create a Stream Analytics project

1. In Visual Studio Code, press **Ctrl+Shift+P** and enter **ASA: Create New Project**. 

    :::image type="content" source="./media/quick-create-visual-studio-code/create-new-project.png" alt-text="Screenshot showing the selection of ASA: Create New Project in the command palette.":::   

1. Enter your project name, like **myASAproj**, and select a folder for your project.

    :::image type="content" source="./media/quick-create-visual-studio-code/create-project-name.png" alt-text="Screenshot showing entering an ASA project name.":::   

1. An ASA project is added to your workspace. It consists of three folders: **Inputs**, **Outputs**, and **Functions**. It also has the query script **(*.asaql)**, a **JobConfig.json** file, and an **asaproj.json** configuration file. 

    :::image type="content" source="./media/quick-create-visual-studio-code/asa-project-files.png" alt-text="Screenshot showing Stream Analytics project files in Visual Studio Code.":::   

     The **asaproj.json** file contains the inputs, outputs, and job configuration settings for submitting the Stream Analytics job to Azure.

    > [!Note]
    > When you're adding inputs and outputs from the command palette, the corresponding paths are added to **asaproj.json** automatically. If you add or remove inputs or outputs on disk directly, you need to manually add or remove them from **asaproj.json**. You can choose to put the inputs and outputs in one place and then reference them in different jobs by specifying the paths in each **asaproj.json** file.

## Define the transformation query

1. Open **myASAproj.asaql** file and add the following query:

   ```sql
   SELECT *
   INTO Output
   FROM Input
   WHERE Temperature > 27
   ```

    :::image type="content" source="./media/quick-create-visual-studio-code/query.png" lightbox="./media/quick-create-visual-studio-code/query.png" alt-text="Screenshot showing the transformation query.":::       

## Configure job input

1. Right-click the **Inputs** folder in your Stream Analytics project. Then select **ASA: Add Input** from the context menu.

    :::image type="content" source="./media/quick-create-visual-studio-code/add-input-from-inputs-folder.png" lightbox="./media/quick-create-visual-studio-code/add-input-from-inputs-folder.png" alt-text="Screenshot showing the ASA: Add input menu in Visual Studio Code.":::   

    Or press **Ctrl+Shift+P** to open the command palette and enter **ASA: Add Input**.
2. Choose **IoT Hub** for the input type.
    
    :::image type="content" source="./media/quick-create-visual-studio-code/iot-hub.png" lightbox="./media/quick-create-visual-studio-code/iot-hub.png" alt-text="Screenshot showing the selection of your IoT hub in VS Code command palette.":::   
3. Choose **Select from Azure subscriptions** from the drop-down menu, and then press **ENTER**. 
1. Enter **Input** for the name, and then press **ENTER**. 
1. Under **Inputs** folder, you see an **IoTHub1.json** file is created.
1. In the JSON file, confirm that **Input** is specified **Name**. 
1. In the JSON editor for **Input.json**, choose **Select from your subscriptions**, and then select your Azure subscription that has the IoT hub.  

    :::image type="content" source="./media/quick-create-visual-studio-code/select-from-your-azure-subscriptions.png" lightbox="./media/quick-create-visual-studio-code/select-from-your-azure-subscriptions.png" alt-text="Screenshot showing the JSON editor with Select from your subscriptions link.":::       
1. In the JSON editor, choose **Select an IoT Hub**, and then select the IoT hub you created. 

    :::image type="content" source="./media/quick-create-visual-studio-code/select-iot-hub-json.png" lightbox="./media/quick-create-visual-studio-code/select-iot-hub-json.png" alt-text="Screenshot showing the JSON editor with Select an IoT Hub link.":::       
1. By default, the `SharedAccessPolicyName` should be set to `iothubowner`. If not, choose **Select a Shared Access Policy Name** link, and then select **iothubowner** from the drop-down list. 
1. The `SharedAccessPolicyKey` value should be automatically set.

   <!-- You can use the CodeLens feature to help you enter a string, select from a drop-down list, or change the text directly in the file. The following screenshot shows **Select from your Subscriptions** as an example. The credentials are auto-listed and saved in local credential manager.

    :::image type="content" source="./media/quick-create-visual-studio-code/configure-input.png" lightbox="./media/quick-create-visual-studio-code/configure-input.png" alt-text="Screenshot showing the launch of CodeLens feature in VS Code."::: 

    After you select a subscription, **select an IoT hub** if you have multiple hubs in that subscription. 

    :::image type="content" source="./media/quick-create-visual-studio-code/select-iot-hub.png" lightbox="./media/quick-create-visual-studio-code/select-iot-hub.png" alt-text="Screenshot showing the selection of your IoT hub in VS Code.":::  -->

5. Select **Preview data** to see if the input data is successfully configured for your job. It will fetch a sample of your IoT Hub and show in the preview window. 

    :::image type="content" source="./media/quick-create-visual-studio-code/preview-live-input.png" lightbox="./media/quick-create-visual-studio-code/preview-live-input.png"  alt-text="Screenshot showing the preview of input data in your IoT hub."::: 



## Configure job output

1. Right-click **Outputs** in the explorer, and select **ASA: Add Output**. 
2. Choose **Data Lake Storage Gen2/Blob Storage** for the sink type in the drop-down list. 
1. Choose **Select from Azure subscriptions** 
1. Enter **Output** for the name of the alias and press ENTER. This output name is used for **INTO** statement in the query.
1. In the JSON editor for **Output.json**, choose **Select from your subscriptions**, and then select your Azure subscription that has the Azure Storage account
1. If you need to change the storage account that's automatically filled, choose **Select a Storage account**, and then select your Azure Storage account. Storage account names are automatically detected if they're created in the same subscription.
1. If you need to change the container name, choose **Select a container**, and select the blob container you created. 
 
  <!-- |Path Pattern|output|Enter the name of a file path to be created within the container.| -->

   :::image type="content" source="./media/quick-create-visual-studio-code/configure-output.png" lightbox="./media/quick-create-visual-studio-code/configure-output.png" alt-text="Screenshot showing the configuration of output for the Stream Analytics job."::: 



## Compile the script and submit to Azure

Script compilation checks syntax and generates the Azure Resource Manager templates for automatic deployment. 

1. Right-click the script file in the explorer window, point to **ASA: Compile Script**, and then select **ASA: ARM Template V2 (recommended)**.

   :::image type="content" source="./media/quick-create-visual-studio-code/compile-script-2.png" lightbox="./media/quick-create-visual-studio-code/compile-script-2.png" alt-text="Screenshot showing the compilation of script option from the Stream Analytics explorer in VS Code."::: 
2. After compilation, you see a **Deploy** folder under your project with two Azure Resource Manager templates. These two files are used for automatic deployment.

    :::image type="content" source="./media/quick-create-visual-studio-code/deployment-templates.png" lightbox="./media/quick-create-visual-studio-code/deployment-templates.png" alt-text="Screenshot showing the generated deployment templates in the project folder."::: 
3. Select **Submit to Azure** in the query editor.

    :::image type="content" source="./media/quick-create-visual-studio-code/submit-job.png" lightbox="./media/quick-create-visual-studio-code/submit-job.png"  alt-text="Screenshot showing the Submit job button to submit the Stream Analytics job to Azure."::: 
3. In the **Submit** window, follow these steps:
    1. Select your Azure **subscription**. 
    1. Select an Azure **resource group**.
    1. Select the **region** where you want to create the Stream Analytics job. 
    1. Then, select **Submit**. 

        :::image type="content" source="./media/quick-create-visual-studio-code/submit-options.png" alt-text="Screenshot showing Submit options.":::         
4. Select **Publish to Azure** and complete. Wait for it to open a new tab **Cloud Job View** showing your job's status. 
    
    :::image type="content" source="./media/quick-create-visual-studio-code/publish-to-azure.png" lightbox="./media/quick-create-visual-studio-code/publish-to-azure.png"  alt-text="Screenshot showing the publish to Azure button in VS Code."::: 

## Start the Stream Analytics job and check output

1. On the **Cloud Job View** tab, select **Start** to run your job in the cloud. 

    :::image type="content" source="./media/quick-create-visual-studio-code/start-asa-job-vs-code.png" lightbox="./media/quick-create-visual-studio-code/start-asa-job-vs-code.png"  alt-text="Screenshot showing the Start job button in the Cloud view page."::: 
1. On the **Start streaming job** window, select **OK**. This process might take a few minutes to complete.
2. If your job starts successfully, the job status is changed to **Running**. You can see a logical diagram showing how your ASA job is running.

    :::image type="content" source="./media/quick-create-visual-studio-code/job-running-status.png" lightbox="./media/quick-create-visual-studio-code/job-running-status.png"  alt-text="Screenshot showing the job running status in VS Code."::: 

3. To view the output results, you can open the blob storage in the Visual Studio Code extension or in the Azure portal.

    :::image type="content" source="./media/quick-create-visual-studio-code/output-files.png" lightbox="./media/quick-create-visual-studio-code/output-files.png" alt-text="Screenshot showing the output file in the Blob container.":::

    Download and open the file to see output.

    ```json
    {"messageId":11,"deviceId":"Raspberry Pi Web Client","temperature":28.165519323167562,"humidity":76.875393581654379,"EventProcessedUtcTime":"2022-09-01T22:53:58.1015921Z","PartitionId":3,"EventEnqueuedUtcTime":"2022-09-01T22:52:57.6250000Z","IoTHub":{"MessageId":null,"CorrelationId":null,"ConnectionDeviceId":"MyASAIoTDevice","ConnectionDeviceGenerationId":"637976642928634103","EnqueuedTime":"2022-09-01T22:52:57.6290000Z"}}
    {"messageId":14,"deviceId":"Raspberry Pi Web Client","temperature":29.014941877871451,"humidity":64.93477299527828,"EventProcessedUtcTime":"2022-09-01T22:53:58.2421545Z","PartitionId":3,"EventEnqueuedUtcTime":"2022-09-01T22:53:03.6100000Z","IoTHub":{"MessageId":null,"CorrelationId":null,"ConnectionDeviceId":"MyASAIoTDevice","ConnectionDeviceGenerationId":"637976642928634103","EnqueuedTime":"2022-09-01T22:53:03.6140000Z"}}
    {"messageId":17,"deviceId":"Raspberry Pi Web Client","temperature":28.032846241745975,"humidity":66.146114343897338,"EventProcessedUtcTime":"2022-09-01T22:53:58.2421545Z","PartitionId":3,"EventEnqueuedUtcTime":"2022-09-01T22:53:19.5960000Z","IoTHub":{"MessageId":null,"CorrelationId":null,"ConnectionDeviceId":"MyASAIoTDevice","ConnectionDeviceGenerationId":"637976642928634103","EnqueuedTime":"2022-09-01T22:53:19.5830000Z"}}
    {"messageId":18,"deviceId":"Raspberry Pi Web Client","temperature":30.176185593576143,"humidity":72.697359909427419,"EventProcessedUtcTime":"2022-09-01T22:53:58.2421545Z","PartitionId":3,"EventEnqueuedUtcTime":"2022-09-01T22:53:21.6120000Z","IoTHub":{"MessageId":null,"CorrelationId":null,"ConnectionDeviceId":"MyASAIoTDevice","ConnectionDeviceGenerationId":"637976642928634103","EnqueuedTime":"2022-09-01T22:53:21.6140000Z"}}
    {"messageId":20,"deviceId":"Raspberry Pi Web Client","temperature":27.851894248213021,"humidity":71.610229530268214,"EventProcessedUtcTime":"2022-09-01T22:53:58.2421545Z","PartitionId":3,"EventEnqueuedUtcTime":"2022-09-01T22:53:25.6270000Z","IoTHub":{"MessageId":null,"CorrelationId":null,"ConnectionDeviceId":"MyASAIoTDevice","ConnectionDeviceGenerationId":"637976642928634103","EnqueuedTime":"2022-09-01T22:53:25.6140000Z"}}
    {"messageId":21,"deviceId":"Raspberry Pi Web Client","temperature":27.718624694772238,"humidity":66.540445035685153,"EventProcessedUtcTime":"2022-09-01T22:53:58.2421545Z","PartitionId":3,"EventEnqueuedUtcTime":"2022-09-01T22:53:48.0820000Z","IoTHub":{"MessageId":null,"CorrelationId":null,"ConnectionDeviceId":"MyASAIoTDevice","ConnectionDeviceGenerationId":"637976642928634103","EnqueuedTime":"2022-09-01T22:53:48.0830000Z"}}
    {"messageId":22,"deviceId":"Raspberry Pi Web Client","temperature":27.7849054424326,"humidity":74.300662748167085,"EventProcessedUtcTime":"2022-09-01T22:54:09.3393532Z","PartitionId":3,"EventEnqueuedUtcTime":"2022-09-01T22:54:09.2390000Z","IoTHub":{"MessageId":null,"CorrelationId":null,"ConnectionDeviceId":"MyASAIoTDevice","ConnectionDeviceGenerationId":"637976642928634103","EnqueuedTime":"2022-09-01T22:54:09.2400000Z"}}
    {"messageId":28,"deviceId":"Raspberry Pi Web Client","temperature":30.839892925680324,"humidity":76.237611741451786,"EventProcessedUtcTime":"2022-09-01T22:54:47.8053253Z","PartitionId":3,"EventEnqueuedUtcTime":"2022-09-01T22:54:47.6180000Z","IoTHub":{"MessageId":null,"CorrelationId":null,"ConnectionDeviceId":"MyASAIoTDevice","ConnectionDeviceGenerationId":"637976642928634103","EnqueuedTime":"2022-09-01T22:54:47.6150000Z"}}
    {"messageId":29,"deviceId":"Raspberry Pi Web Client","temperature":30.561040300759053,"humidity":78.3845172058103,"EventProcessedUtcTime":"2022-09-01T22:54:49.8070489Z","PartitionId":3,"EventEnqueuedUtcTime":"2022-09-01T22:54:49.6030000Z","IoTHub":{"MessageId":null,"CorrelationId":null,"ConnectionDeviceId":"MyASAIoTDevice","ConnectionDeviceGenerationId":"637976642928634103","EnqueuedTime":"2022-09-01T22:54:49.5990000Z"}}
    {"messageId":31,"deviceId":"Raspberry Pi Web Client","temperature":28.163585438418679,"humidity":60.0511571297096,"EventProcessedUtcTime":"2022-09-01T22:55:25.1528729Z","PartitionId":3,"EventEnqueuedUtcTime":"2022-09-01T22:55:24.9050000Z","IoTHub":{"MessageId":null,"CorrelationId":null,"ConnectionDeviceId":"MyASAIoTDevice","ConnectionDeviceGenerationId":"637976642928634103","EnqueuedTime":"2022-09-01T22:55:24.9120000Z"}}
    {"messageId":32,"deviceId":"Raspberry Pi Web Client","temperature":31.00503387156985,"humidity":78.68821066044552,"EventProcessedUtcTime":"2022-09-01T22:55:43.2652127Z","PartitionId":3,"EventEnqueuedUtcTime":"2022-09-01T22:55:43.0480000Z","IoTHub":{"MessageId":null,"CorrelationId":null,"ConnectionDeviceId":"MyASAIoTDevice","ConnectionDeviceGenerationId":"637976642928634103","EnqueuedTime":"2022-09-01T22:55:43.0520000Z"}}
    ```

## Clean up resources

When no longer needed, delete the resource group, the Stream Analytics job, and all related resources. Deleting the job avoids billing the streaming units consumed by the job. If you're planning to use the job in future, you can stop it and restart it later when you need. If you aren't going to continue to use this job, delete all resources created by this quickstart by using the following steps:

1. From the left menu in the Azure portal, select **Resource groups** and then select the name of the resource that you created.  

2. On your resource group page, select **Delete**. Enter the name of the resource to delete in the text box, and then select **Delete**.

## Next steps

To learn more about ASA Tools extension for Visual Studio Code, continue to the following articles:

* [Test Stream Analytics queries locally with sample data using Visual Studio Code](visual-studio-code-local-run.md)

* [Test Azure Stream Analytics jobs locally against live input with Visual Studio Code](visual-studio-code-local-run-live-input.md)

* [Use Visual Studio Code to view Azure Stream Analytics jobs](visual-studio-code-explore-jobs.md)

* [Set up CI/CD pipelines by using the npm package](./cicd-overview.md)
