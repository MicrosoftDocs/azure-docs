---
author: eric-urban
ms.service: azure-ai-speech
ms.date: 02/17/2023
ms.topic: include
ms.author: eur
---

In this quickstart, you'll use Speech and Language services to recognize intents from audio data captured from a microphone. Specifically, you'll use the Speech service to recognize speech, and a [Conversational Language Understanding (CLU)](../../../../language-service/conversational-language-understanding/overview.md) model to identify intents. 

> [!IMPORTANT]
> Conversational Language Understanding (CLU) is available for C# and C++ with the [Speech SDK](~/articles/ai-services/speech-service/speech-sdk.md) version 1.25 or later. 

