{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffdc8f83-db17-42b3-b630-9e739e224c69",
   "metadata": {},
   "source": [
    "# **OCR for Sensitive Data Protection in Images**\n",
    "                                                    \n",
    "This notebook shows an example of how Azure AI OCR can help detect and protect sensitive data embedded in images. Azure AI OCR extracts text from an image of a Social Security Card, the extracted text is then passed to Azure PII detection API. The PII detection API detects, and sensors sensitive text extracted from the image. \n",
    "\n",
    "## **Prerequisites**\n",
    "•\tAzure subscription - [Create one for free](https://azure.microsoft.com/en-us/free/ai-services/).  \n",
    "•\tPython 3.7 or later  \n",
    "•\tOnce you have your Azure subscription, create an [Azure AI Services Resource](https://ms.portal.azure.com/#view/Microsoft_Azure_Marketplace/GalleryItemDetailsBladeNopdl/id/Microsoft.CognitiveServicesAllInOne/selectionMode~/false/resourceGroupId//resourceGroupLocation//dontDiscardJourney~/false/selectedMenuId/home/launchingContext~/%7B%22galleryItemId%22%3A%22Microsoft.CognitiveServicesAllInOne%22%2C%22source%22%3A%5B%22GalleryFeaturedMenuItemPart%22%2C%22VirtualizedTileDetails%22%5D%2C%22menuItemId%22%3A%22home%22%2C%22subMenuItemId%22%3A%22Search%20results%22%2C%22telemetryId%22%3A%2283634c2f-d125-43ab-97bc-7a640bbe21b8%22%7D/searchTelemetryId/371171fe-5873-4a59-b146-a99c27091437) in the Azure portal to get your key and endpoint. After it deploys, select Go to resource. You'll need the key and endpoint from the resource you create to connect your application to the API. You'll paste your key and endpoint into the code below.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5987dd9-57f5-435f-a766-7e08bfdd63bb",
   "metadata": {},
   "source": [
    "## Architectural Diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd49e5b-c583-4c04-9610-d5583610aaec",
   "metadata": {},
   "source": [
    "![Architectural Diagram](diagram.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d69679d-a04a-47f2-a644-564d6dcf9489",
   "metadata": {},
   "source": [
    "## Example Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a32e8c-38c5-49bb-8a10-e1bee8f6a2d2",
   "metadata": {},
   "source": [
    "![Example Image](example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faadf9ea-e890-485a-a1bf-b1c252a769cc",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9781de39-d8b7-458d-8855-375996fedb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install azure-ai-vision-imageanalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ee10cf-c8f5-4172-9c86-ca9bb3c3edc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install azure-ai-textanalytics==5.2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37fa7a9-3a91-4eb7-ae83-336f174a01c1",
   "metadata": {},
   "source": [
    "## Example Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ceb68a-bbe6-4259-a3fa-7e2b199b8420",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.vision.imageanalysis import ImageAnalysisClient\n",
    "from azure.ai.vision.imageanalysis.models import VisualFeatures\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "from azure.core.exceptions import HttpResponseError\n",
    "\n",
    "# Set the values of your computer vision endpoint and computer vision key\n",
    "# as environment variables:\n",
    "try:\n",
    "    endpoint = \"https://dybetest1.cognitiveservices.azure.com/\"\n",
    "    key = \"62ee3f49132c4f289f28229f254d8775\"\n",
    "except KeyError:\n",
    "    print(\"Missing ENDPOINT' or 'KEY'\")\n",
    "    print(\"Set them before running this sample.\")\n",
    "    exit()\n",
    "\n",
    "# Create an Image Analysis client\n",
    "image_analysis_client = ImageAnalysisClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(key)\n",
    ")\n",
    "\n",
    "#Create an Azure Text Analytics client\n",
    "text_analytics_client = TextAnalyticsClient(\n",
    "            endpoint=endpoint, \n",
    "            credential=AzureKeyCredential(key)\n",
    ")\n",
    "\n",
    "\n",
    "# Example method for detecting sensitive information (PII) from text in images \n",
    "def pii_recognition_example(client):\n",
    "\n",
    "    #Get text from the image using Image Analysis OCR\n",
    "    ocr_result = image_analysis_client.analyze_from_url(\n",
    "    image_url=\"https://resources.ssnsimple.com/wp-content/uploads/2019/11/social-security-number.jpg\",\n",
    "    visual_features=[VisualFeatures.READ],\n",
    ")\n",
    "   \n",
    "    documents = [' '.join([line['text'] for line in ocr_result.read.blocks[0].lines])]\n",
    "  \n",
    "    print(documents)\n",
    "\n",
    "    #Detect sensitive information in OCR output\n",
    "    response = text_analytics_client.recognize_pii_entities(documents, language=\"en\")\n",
    "    result = [doc for doc in response if not doc.is_error]\n",
    "    \n",
    "    for doc in result:\n",
    "        print(\"Redacted Text: {}\".format(doc.redacted_text))\n",
    "        for entity in doc.entities:\n",
    "            print(\"Entity: {}\".format(entity.text))\n",
    "            print(\"\\tCategory: {}\".format(entity.category))\n",
    "            print(\"\\tConfidence Score: {}\".format(entity.confidence_score))\n",
    "            print(\"\\tOffset: {}\".format(entity.offset))\n",
    "            print(\"\\tLength: {}\".format(entity.length))\n",
    "            \n",
    "pii_recognition_example(text_analytics_client)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
