> [!IMPORTANT]
> Items marked (preview) in this article are currently in public preview.
> The preview version is provided without a service level agreement, and it's not recommended for production workloads. Certain features might not be supported or might have constrained capabilities.
> For more information, see [Supplemental Terms of Use for Microsoft Azure Previews](https://azure.microsoft.com/support/legal/preview-supplemental-terms/).

## What is 'Foundation Models in AzureML'?
In recent years, advancements in AI have led to the rise of large foundation models that are trained on a vast quantity of data and that can be easily adapted to a wide variety of applications across various industries. This emerging trend gives rise to a unique opportunity for enterprises to build and use these foundation models in their deep learning workloads.

<br>'Foundation Models in AzureML'<br> provides AzureML native capabilities that enable customers to build and operationalize open-source foundation models at scale. It includes the following capabilities -

* A comprehensive repository of top 30+ language models from Hugging Face, made available in the model catalog via AzureML built-in registry
* Support for base model inferencing using pretrained models
* Ability to finetune the models using your own training data. Finetuning is supported for the following language tasks - Text Classification, Token Classification, Question Answering, Summarization and Translation
* Ability to evaluate the models using your own test data
* State of the art performance and throughput in Azure hardware

###  Key user advantages 
Hereâ€™s a summary of key user benefits, as compared to what is available prior -
![image](https://user-images.githubusercontent.com/36742198/208785135-253c8b19-489a-4ffb-b2be-48100401bf90.png)

### Finetuning foundation models using your own training data
In order to improve model performance in your workload, you might want to fine tune a foundation model using your own training data. You can easily finetune these foundation models using either code based notebook samples or by using the Finetune UI wizard linked from the model card.
