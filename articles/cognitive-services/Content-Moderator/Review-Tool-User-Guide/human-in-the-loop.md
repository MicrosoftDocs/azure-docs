---
title: How humans improve automated content moderation for Content Moderator | Microsoft Docs
description: Humans work with automated content moderation to add real-world context that machine learning can't provide.
services: cognitive-services
author: sanjeev3
manager: mikemcca

ms.service: cognitive-services
ms.technology: content-moderator
ms.topic: article
ms.author: sajagtap
---

# Human-in-the-Loop #

Why do we need a human review tool with automated content moderation powered by machine learning and AI? 

We think you get the best results when humans and machines work together on harder cases. Humans can effectively augment machine learning models in situations where the prediction confidence has to be assisted or tempered within a real world context. 

Humans can focus on the edge cases and help the models learn and get better over time. The result is a hybrid, automated content moderation process that performs better than if the humans or machines were working alone.

## How the Review tool helps ##

The human review tool when used in conjunction with our automated moderation APIs allows you to accomplish these important tasks in relation to the content moderation life cycle.

1. Automate the creation of human reviews from the underlying moderation API results
2. Use one tool (Review Tool and API) to moderate multiple formats (text, image, and video - coming soon)
3. Assign or escalate content reviews to multiple review teams organized by content category or experience level.
4. Use default workflows or define custom workflows with flexible rules, and without writing any code.
5. Add human review to any API or business process by simply building a connector.
6. Use the default connectors to review results from Microsoft PhotoDNA, Text Analytics, and Face APIs.
7. Get key performance metrics on your content moderation processes.
