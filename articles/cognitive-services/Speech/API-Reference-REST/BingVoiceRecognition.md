---
title: Bing Speech Recognition REST API in Microsoft Cognitive Services | Microsoft Docs
description: Use the Bing Speech Recognition REST API in contexts that need cloud-based speech recognition capabilities.
services: cognitive-services
author: priyaravi20
manager: yanbo

ms.service: cognitive-services
ms.technology: speech
ms.topic: article
ms.date: 02/28/2017
ms.author: prrajan
---

# Bing Speech Recognition API

## <a name="Introduction">Introduction</a>
This documentation describes the Bing Speech Recognition REST API that exposes an HTTP interface which enables developers to transcribe voice queries. The Bing Speech Recognition API may be used in many different contexts that need cloud-based speech recognition capabilities. 

## <a name="VoiceRecReq">Speech Recognition Request</a>
### <a name="Authorize">Authenticate the API call</a>

Every request requires a JSON Web Token (JWT) access token. The JWT access token is passed through in the Speech request header. The token has an expiry time of 10 minutes. See [Get Started for Free](https://www.microsoft.com/cognitive-services/en-US/sign-up?ReturnUrl=/cognitive-services/en-us/subscriptions?productId=%2fproducts%2fBing.Speech.Preview) for information about subscribing and obtaining API keys used to retrieve valid JWT access tokens.

The API key is passed to the token service, for example:

```
POST https://api.cognitive.microsoft.com/sts/v1.0/issueToken
Content-Length: 0
```

The required header for token access is:

Name	| Format	| Description, Example and Use
---------|---------|--------
Ocp-Apim-Subscription-Key |	ASCII	| Your subscription key.

The token service returns the JWT access token as text/plain. Then the JWT is passed as a Base64 access_token to the Speech endpoint as an Authorization header prefixed with the string Bearer, for example:

`Authorization: Bearer [Base64 access_token]`

### <a name="SpeechService">Access the Speech Service Endpoint</a>

Clients must use the following endpoint to access the service and build voice enabled applications: 

 `https://speech.platform.bing.com/recognize`

>[!NOTE]
>Until you have acquired an `access token` with your subscription key as described above this link will generate a 403 Response Error.

The API uses HTTP POST to upload audio. The API supports [chunked transfer encoding](https://en.wikipedia.org/wiki/Chunked_transfer_encoding) for efficient audio streaming. For live transcription scenarios, it is recommended you use chunked transfer encoding to stream the audio to the service while the user is speaking. Other implementations result in higher user-perceived latency. 

Your application must indicate the end of the audio to determine start and end of speech, which in turn is used by the service to determine the start and end of the request. You may not upload more than 10 seconds of audio in any one request and the total request duration cannot exceed 14 seconds. 

### <a name="InputParam">Input Parameters</a>

Inputs to the Bing Speech Recognition API are expressed as HTTP query parameters. Parameters in the POST body are treated as audio content. Unsafe characters should be escaped following the W3C URL spec ([http://www.w3.org/Addressing/URL/url-spec.txt](http://www.w3.org/Addressing/URL/url-spec.txt)). A request with more than one instance of any parameter will result in an error response (HTTP 400). 

Following is a complete list of required and optional input parameters.

#### <a name="ReqParam">Required Parameters</a>

Name  |Format  |Description, example and use  
---------|---------|---------
Version     |  Digits and "."       |    The API version being used by the client. The required value is 3.0.   **Example:** version=3.0   
requestid     |    GUID     |        A globally unique identifier generated by the client for this request. **Example:** requestid=b2c95ede-97eb-4c88-81e4-80f32d6aee54
appID     |   GUID      |   A globally unique identifier used for this application. Always use appID = D4D52672-91D7-4C74-8AD8-42B1D98141A5. Do not generate a new GUID as it will be unsupported.     
format     |  UTF-8       |      Specifies the desired format of the returned data. The required value is JSON. **Example:** format=json. 
locale     |    UTF-8 (IETF Language Tag)     |    Language code of the audio content in IETF RFC 5646. Case does not matter. **Example:** locale=en-US. 
device.os    |     UTF-8    |     Operating system the client is running on. This is an open field but we encourage clients to use it consistently across devices and applications. Suggested values: Windows OS, Windows Phone OS, XBOX, Android, iPhone OS. **Example:** device.os=Windows Phone OS.
scenarios     |    UTF-8     |    The context for performing a recognition. The supported values are: ulm, websearch. **Example:** scenarios=ulm.     
instanceid      |    GUID     |      A globally unique device identifier of the device making the request. **Example:** instanceid=b2c95ede-97eb-4c88-81e4-80f32d6aee54
  
#### <a name="OptParam">Optional Parameters</a>

>[!NOTE]
>The values below are used either for performing the request or to manage the service operationally. 

Name  |Format  |Description and example  
---------|---------|---------
maxnbest     |     Integer    |       Maximum number of results the voice application API should return. The default is 1. The maximum is 5. **Example:** maxnbest=3   
result.profanitymarkup     |     0/1    |      Scan the result text for words included in an offensive word list. If found, the word will be delimited by bad word tag. **Example:** result.profanity=1 (0 means off, 1 means on, default is 1.)

### <a name="SampleImplementation">REST API Implementation Sample

A working code sample of REST API implementation can be found [here](https://oxfordportal.blob.core.windows.net/speech/doc/recognition/Program.cs). 

###  <a name="SampleVoiceRR">Example Speech Recognition Request</a>

The following is an example of a request where the audio is supplied as part of a recognition request: 
   
```
POST /recognize?scenarios=catsearch&appid=f84e364c-ec34-4773-a783-73707bd9a585&locale=en-US&device.os=wp7&version=3.0&format=xml&requestid=1d4b6030-9099-11e0-91e4-0800200c9a66&instanceid=1d4b6030-9099-11e0-91e4-0800200c9a66 HTTP/1.1
Host: speech.platform.bing.com
Content-Type: audio/wav; samplerate=16000
Authorization: Bearer [Base64 access_token]

(audio data)
```
### <a name="Codecs">Supported Codecs</a>
The Speech Recognition API supports audio/wav using the following codecs: 
* PCM single channel
* Siren
* SirenSR

## <a name="VoiceRecResponse">Speech Recognition Responses</a>
The API response is returned in JSON format. The value of the “name” tag has the post-inverse text normalization result. The value of the “lexical” tag has the pre-inverse text normalization result. 

### <a name="NormalResponse">Normal response</a>

#### <a name="Schema1">Schema 1</a>
Schema Legend: 

* < ... >  means optional
* "[ ]" represents a json array
* "{ }" represents a json object  
* "*" indicates that the object can be defined multiple times

  
```
JSON-text: version header <results> // result must be always and only present when status = "success" 
version: string // The API version "3.0" — the value the client passed and consequently the API version that serviced the request. 
header: {status scenario <name> <lexical> properties} // name and lexical are always and only present in the case of "status" = “success”
     status: "success"/ "error"/ "false reco"// 'false reco' is returned only for 2.0 responses when NOSPEECH OR FALSERECO is 1. This is done to maintain backward compatibility. 
     scenario: string // the scenario this recognition result came from. 
     name: string // formatted recognition result. Profane terms are surrounded with <profanity> tags. 
     lexical: string // text of what was spoken. Profane terms are surrounded with <profanity> tags.
     properties: {requestid <NOSPEECH> <FALSERECO> <HIGHCONF> <ERROR>} 
           requestid: string // this is a uuid identifying the requestid to be sent with the associated logs. It should be used as the "server.requestid" parameter value in the subsequent logging API request. 
           NOSPEECH: 1 // set when no speech was detected on the sent audio. 
           FALSERECO: 1 // set when no matches were found for the sent audio. 
           HIGHCONF: 1 // set when the header result is determined to be of high-confidence. 
           MIDCONF: 1 // set when the header result is determined to be of medium-confidence.
           LOWCONF: 1 // set when the header result is determined to be of low-confidence. 
           ERROR: 1 // set when there was an error generating a response. 
results: [{scenario name lexical confidence pronunciation tokens}*] // n-best list of results ordered by confidence. 
     scenario: string // the scenario this recognition result came from. 
     name: string // formatted recognition result. Profane terms are surrounded with <profanity> tags. 
     lexical: string // text of what was spoken. Profane terms are surrounded with <profanity> tags. 
     properties: {<HIGHCONF>} 
           HIGHCONF: 1 // set when the header result is determined to be of high-confidence. 
           MIDCONF: 1 // set when the header result is determined to be of medium-confidence. 
           LOWCONF: 1 // set when the header result is determined to be of low-confidence. 

```
  
#### <a name="Schema2">Schema 2</a>

* **speechbox-root:**  
  * **child tags:** version, header, results 
  * **value:** none 
  * **attributes:** none 

* **version:** 
  * **child tags:** none 
  * **value:** string, the API version "3.0" 
  * **attributes:** none 

* **header:**  
  * **tags:** status, name, lexical, properties 
  * **value:** none 
  * **attributes:** none 

* **status:**  
  * **child tags:** none 
  * **value:** string, "success" or "error" 
  * **attributes:** none 

* **scenario:**  
  * **child tags:** none 
  * **value:** string, the scenario parameter value 
  * **attributes:** none 

* **name:**  
  * **child tags:** none 
  * **value:** string, formatted recognition result 
  * **attributes:** none 

* **lexical:**  
  * **child tags:** none 
  * **value:** string, text of what was spoken 
  * **attributes:** none 

* **properties:**  
  * **child tags:** property 
  * **value: none** 
  * **attributes:** none 

* **property:**  
  * **child tags:** none 
  * **value:** string, the property value 
  * **attributes:** { name: the property name } 
  * **other information:**  Properties based in the header have the following valid names: requestid, NOSPEECH, FALSERECO. 
Properties based in the result portion consist of only HIGHCONF.
  * **valid property values:**  requestid: a valid GUID string
NOSPEECH: “1” to indicate a no speech false recognition
FALSERECO: “1” to indicate that there were no interpretations
HIGHCONF: “1” to indicate high confidence (currently above .5 threshold)
MIDCONF: “1” to indicate medium-confidence
LOWCONF: “1” to indicate low-confidence
* **results:**  
  * **child tags:** result 
  * **value:** none 
  * **attributes:** none 

* **result:**  
  * **child tags:** name, lexical, confidence, tokens 
  * **value:** none 
  * **attributes:** none 

* **confidence:** 
  * **child tags:** none 
  * **value:** float, indicates result confidence 
  * **attributes:** none 

* **tokens:**  
  * **child tags:** token 
  * **value:** none 
  * **attributes:** none 

* **token:**  
  * **child tags:** name, lexical, pronunciation 
  * **value:** none 
  * **attributes:** none 

* **pronunciation:**  
  * **child tags:** none 
  * **value:** string, the IPA pronunciation of this token 
  * **attributes:** none 

#### <a name="SuccessfulRecResponse">Successful Recognition Response</a>

Example JSON response for a successful voice search. The comments and formatting of the JSON below is for example reasons only. The real result will omit indentations, spaces, smart quotes, comments, etc. 

```
HTTP/1.1 200 OK
Content-Length: XXX
Content-Type: application/json; charset=UTF-8
{
 
  "version":"3.0", 
  "header":{
    "status":"success",
    "scenario":"websearch",
    "name":"Mc Dermant Autos",
    “lexical”:”mac dermant autos”,
    "properties":{
      "requestid":"ABDDD97E-171F-4B75-A491-A977027B0BC3"
    },
  "results":[{
    # Formatted result
    "name":"Mc Dermant Autos",
    # The text of what was spoken
    “lexical”:”mac dermant autos”,
    # Words that make up the result; a word can include a space if there
    # isn’t supposed to be a pause between words when speaking them
    "tokens":[{ 
      # The text in the grammar that matched what was spoken for this token
      "token":"mc dermant", 
      # The text of what was spoken for this token
      “lexical”:”mac dermant”,
      # The IPA pronunciation of this token (I made up M AC DIR MANT; 
      # refer to a real IPA spec for the text of an actual pronunciation)
      “pronunciation”:”M AC DIR MANT”,
    },
    {
      "token":"autos",
      “lexical”:”autos”,
      “pronunciation”:”OW TOS”,
    }],
    “properties”:{
      “HIGHCONF”:”1”
    },
  }],
  }
}

```

```
</speechbox-root>
```
#### <a name="RecFailure">Recognition Failure</a>

Example JSON response for a voice search query where the user’s speech could not be recognized. 


```
HTTP/1.1 200 OK
Content-Length: XXX
Content-Type: application/json; charset=UTF-8

{
   "version":"3.0",
   "results":[{}],
   “header”:{
     "status":"error",
     "scenario":"websearch",
     "properties":{
"requestid":"ABDDD97E-171F-4B75-A491-A977027B0BC3",
       "FALSERECO":"1"
     }
   }
}

```

### <a name="ErrorResponse">Error Responses</a>

* **Http/400 BadRequest:** Will be returned if a required parameter is missing, empty or null, or if the value passed to either a required or optional parameter is invalid. The “Invalid” response includes passing a string value that is longer than the allowed length. A brief description of the problematic parameter will be included. 

* **Http/401 Unauthorized:** Will be returned if the request is not authorized. 

* **Http/502 BadGateway:** Will be returned when the service was unable to perform the recognition. 

* **Http/403 Forbidden:** Will be returned when there are issues with your authentication or quota.

Example response for a voice search request submitted with a bad parameter. This is the error response format regardless of what format the user has requested. 

```
HTTP/1.0 400 Bad Request
Content-Length: XXX
Content-Type: text/plain; charset=UTF-8

Invalid lat parameter specified       
```

## <a name="TrouNSupport">Troubleshooting and Support</a>
Post all questions and issues to the [Bing Speech Service](https://social.msdn.microsoft.com/Forums/en-US/home?forum=SpeechService) MSDN Forum, with complete detail, such as: 
* An example of the full request string (minus the raw audio data).
* If applicable, the full output of a failed request, which includes log IDs.
* The percentage of requests that are failing.


