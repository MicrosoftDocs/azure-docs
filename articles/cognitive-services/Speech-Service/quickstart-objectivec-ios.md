---
title: 'Quickstart: Recognize speech in Objective-C on iOS using the Cognitive Services Speech SDK'
titleSuffix: "Microsoft Cognitive Services"
description: Learn how to recognize speech in Objective-C on iOS using the Cognitive Services Speech SDK
services: cognitive-services
author: chlandsi

ms.service: cognitive-services
ms.technology: Speech
ms.topic: article
ms.date: 09/24/2018
ms.author: chlandsi
---

# Quickstart: Recognize speech in Objective-C on iOS using the Cognitive Services Speech SDK

[!INCLUDE [Selector](../../../includes/cognitive-services-speech-service-quickstart-selector.md)]

In this article, you learn how to create an iOS app in Objective-C using the Cognitive Services Speech SDK to transcribe an audio file with recorded speech to text.

## Prerequisites

* A subscription key for the Speech service. See [Try the speech service for free](get-started.md).
* A Mac with Xcode 9.4.1 installed as iOS development environment. This tutorial targets iOS versions 11.4. If you don't have Xcode yet, you can install it from the [App Store](https://geo.itunes.apple.com/us/app/xcode/id497799835?mt=12).

## Get the Speech SDK for iOS

[!INCLUDE [License Notice](../../../includes/cognitive-services-speech-service-license-notice.md)]

The current version of the Cognitive Services Speech SDK is `1.0.0`.

The Cognitive Services Speech SDK for Mac and iOS can be downloaded as a zip-file from https://aka.ms/csspeech/iosbinary. Download and copy the files to the `speechsdk` subdirectory in your home directory.


## Create an Xcode Project 

Start Xcode, and start a new project by clicking **File** > **New** > **Project**.
In the template selection dialog, choose the "iOS Single View App" template.

In the dialogs that follow, make the following selections:

1. Project Options Dialog
    1. Enter a name for the quickstart app, for example `helloworld`.
    1. Enter an organization name such as `TestOrg`, and an organization identifer such as `testorg`.
    1. Make sure Objective-C is chosen as the language for the project.
    1. Disable all checkboxes for tests and core data.
    ![Project Settings](media/sdk/qs-objectivec-project-settings.png)
1. Select project directory
    1. Choose your home directory to put the project in. This will create a `helloworld` directory in your home directory that contains all the files for the Xcode project.
    1. Disable the creation of a Git repo for this example project.
    1. Adjust the paths to the SDK in the *Project Settings*.
        1. In the **General** tab under the **Linked Frameworks and Libraries** header, add the SDK library as a framework: **Add framework** > **Add other...** > Navigate to `speechsdk/lib/` in your home directory and choose the file `libMicrosoft.CognitiveServices.Speech.core.dylib`.
        1. Go to the **Build Settings** tab and activate **All** settings.
        1. Add the path to SDK headers (`$(SRCROOT)/../speechsdk/include`) to the *Header Search Path* under the **Search Paths** heading.
        ![Header Search Path setting](media/sdk/qs-objectivec-header-search-path.png)
        1. Add the path to the directory containing the library (`$(SRCROOT)/../speechsdk/lib`) to the *Library Search Path* under the **Search Paths** heading.
        ![Library Search Path setting](media/sdk/qs-objectivec-library-search-path.png)
        1. Add the path to the directory containing the library (`$(SRCROOT)/../speechsdk/lib`) to the *Runpath Search Path* under the **Linking** heading.
        ![Runpath Search Path setting](media/sdk/qs-objectivec-runpath-search-path.png)

## Set up the UI

The example app will have a very simple UI: A button to start the processing of the file, and a text label to display the result.
The UI is set up in the `Main.storyboard` part of the project.
Open the XML view of the storyboard by right-clicking the `Main.storyboard` entry of the project tree and selecting **Open As...** > **Source Code**.
Replace the autogenerated XML with this:

[!code-xml[](~/samples-cognitive-services-speech-sdk/quickstart/objectivec-ios/helloworld/helloworld/Base.lproj/Main.storyboard)]

## Add the sample code

1. Download the [sample wav file](https://raw.githubusercontent.com/Azure-Samples/cognitive-services-speech-sdk/f9807b1079f3a85f07cbb6d762c6b5449d536027/samples/cpp/windows/console/samples/whatstheweatherlike.wav) by right-clicking the link and choosing **Save target as...**.
Add the wav file to the project as a resource by dragging it from a Finder window into the root level of the Project view.
Click **Finish** in the following dialog without changing the settings.
1. Replace the contents of the autogenerated `ViewController.m` file by:

   [!code-objectivec[Quickstart Code](~/samples-cognitive-services-speech-sdk/quickstart/objectivec-ios/helloworld/helloworld/ViewController.m#code)]
1. Replace the string `YourSubscriptionKey` with your subscription key.

1. Replace the string `YourServiceRegion` with the [region](regions.md) associated with your subscription (for example, `westus` for the free trial subscription).


## Building and Running the Sample

1. Make the debug output visible (**View** > **Debug Area** > **Activate Console**).
1. Build and run the example code in the iOS simulator by selecting **Product** -> **Run** from the menu or clicking the **Play** button.
1. After you click the "Recognize!" button in the app, you should see the contents of the audio file "What's the weather like?" on the lower part of the simulated screen.

 ![Simulated iOS App](media/sdk/qs-objectivec-simulated-app.png)

[!INCLUDE [Download the sample](../../../includes/cognitive-services-speech-service-speech-sdk-sample-download-h2.md)]
Look for this sample in the `quickstart/objectivec-ios` folder.

## Next steps

> [!div class="nextstepaction"]
> [Get our samples](speech-sdk.md#get-the-samples)
