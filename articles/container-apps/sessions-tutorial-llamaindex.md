---
title: "Tutorial: Use code interpreter sessions in LlamaIndex with Azure Container Apps"
description: Learn to use code interpreter sessions in LlamaIndex on Azure Container Apps.
services: container-apps
author: anthonychu
ms.service: azure-container-apps
ms.custom: devx-track-azurecli, ignite-2024
ms.topic: tutorial
ms.date: 10/11/2024
ms.author: antchu
---

# Tutorial: Use code interpreter sessions in LlamaIndex with Azure Container Apps

[LlamaIndex](https://www.llamaindex.ai/) is a powerful framework for building context-augmented language model (LLM) applications. When you build an AI agent with LlamaIndex, an LLM interprets user input and generates a response. The AI agent often struggles when it needs to perform mathematical and symbolic reasoning to produce a response. By integrating Azure Container Apps dynamic sessions with LlamaIndex, you give the agent a [code interpreter](sessions-code-interpreter.md) to use to perform specialized tasks.

In this tutorial, you learn how to run a LlamaIndex AI agent in a web API. The API accepts user input and returns a response generated by the AI agent. The agent uses a code interpreter in dynamic sessions to perform calculations.

[!INCLUDE [sessions-tutorial-prerequisites](../../includes/container-apps/sessions-tutorial-prerequisites.md)]

## Run the sample app locally

Before you deploy the app to Azure Container Apps, you can run it locally to test it.

### Clone the app

1. Clone the [Azure Container Apps sessions samples repository](https://github.com/Azure-Samples/container-apps-dynamic-sessions-samples).

    ```bash
    git clone https://github.com/Azure-Samples/container-apps-dynamic-sessions-samples.git
    ```

1. Change to the directory that contains the sample app:

    ```bash
    cd container-apps-dynamic-sessions-samples/llamaindex-python-webapi
    ```

[!INCLUDE [container-apps/sessions-tutorial-configure-local](../../includes/container-apps/sessions-tutorial-configure-local.md)]

### Run the app

Before running the sample app, open [*main.py*](https://github.com/Azure-Samples/container-apps-dynamic-sessions-samples/blob/main/llamaindex-python-webapi/main.py) in an editor and review the code. The app uses FastAPI to create a web API that accepts a user message in the query string.

The following lines of code instantiate a *AzureCodeInterpreterToolSpec* and provide it to the LlamaIndex agent:

```python
code_interpreter_tool = AzureCodeInterpreterToolSpec(
    pool_management_endpoint=pool_management_endpoint,
)
agent = ReActAgent.from_tools(code_interpreter_tool.to_tool_list(), llm=llm, verbose=True)
```

When it needs to perform calculations, the agent uses the code interpreter in *AzureCodeInterpreterToolSpec* to run the code. The code is executed in a session in the session pool. By default, a random session identifier is generated when you instantiate the tool. If the agent uses the same tool to run multiple Python code snippets, it uses the same session. To ensure each end user has a unique session, use a separate agent and tool for each user.

*AzureCodeInterpreterToolSpec* is available in the [`llama-index-tools-azure-code-interpreter`](https://pypi.org/project/llama-index-tools-azure-code-interpreter/) package.

[!INCLUDE [container-apps/sessions-tutorial-run-local](../../includes/container-apps/sessions-tutorial-run-local.md)]

[!INCLUDE [container-apps/sessions-tutorial-deploy](../../includes/container-apps/sessions-tutorial-deploy.md)]

[!INCLUDE [container-apps/sessions-tutorial-clean-up](../../includes/container-apps/sessions-tutorial-clean-up.md)]

## Next steps

> [!div class="nextstepaction"]
> [Code interpreter sessions](./sessions-code-interpreter.md)
